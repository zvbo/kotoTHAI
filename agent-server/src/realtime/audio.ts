import { EventEmitter } from 'events';
import { Transform, TransformCallback } from 'stream';

/**
 * éŸ³é¢‘æ ¼å¼é…ç½®
 */
export interface AudioConfig {
  sampleRate: number;
  channels: number;
  bitDepth: number;
  format: 'pcm16' | 'g711_ulaw' | 'g711_alaw';
}

/**
 * é»˜è®¤éŸ³é¢‘é…ç½®
 */
export const DEFAULT_AUDIO_CONFIG: AudioConfig = {
  sampleRate: 24000, // OpenAI Realtime APIæ¨èçš„é‡‡æ ·ç‡
  channels: 1,       // å•å£°é“
  bitDepth: 16,      // 16ä½æ·±åº¦
  format: 'pcm16'    // PCM 16ä½æ ¼å¼
};

/**
 * éŸ³é¢‘å¤„ç†å™¨
 * è´Ÿè´£éŸ³é¢‘æµçš„ç¼–ç ã€è§£ç å’Œæ ¼å¼è½¬æ¢
 */
export class AudioProcessor extends EventEmitter {
  private config: AudioConfig;
  private inputBuffer: Buffer = Buffer.alloc(0);
  private outputBuffer: Buffer = Buffer.alloc(0);

  constructor(config: AudioConfig = DEFAULT_AUDIO_CONFIG) {
    super();
    this.config = config;
  }

  /**
   * å¤„ç†æ¥è‡ªWebRTCçš„éŸ³é¢‘æ•°æ®
   */
  processWebRTCAudio(audioData: Buffer): Buffer {
    try {
      // å°†WebRTCéŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºOpenAI Realtime APIæ ¼å¼
      const processedAudio = this.convertToRealtimeFormat(audioData);
      
      console.log(`ğŸµ å¤„ç†WebRTCéŸ³é¢‘: ${audioData.length} bytes -> ${processedAudio.length} bytes`);
      
      return processedAudio;
    } catch (error) {
      console.error('âŒ å¤„ç†WebRTCéŸ³é¢‘å¤±è´¥:', error);
      return Buffer.alloc(0);
    }
  }

  /**
   * å¤„ç†æ¥è‡ªOpenAIçš„éŸ³é¢‘æ•°æ®
   */
  processOpenAIAudio(audioData: Buffer): Buffer {
    try {
      // å°†OpenAIéŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWebRTCæ ¼å¼
      const processedAudio = this.convertToWebRTCFormat(audioData);
      
      console.log(`ğŸ¤– å¤„ç†OpenAIéŸ³é¢‘: ${audioData.length} bytes -> ${processedAudio.length} bytes`);
      
      return processedAudio;
    } catch (error) {
      console.error('âŒ å¤„ç†OpenAIéŸ³é¢‘å¤±è´¥:', error);
      return Buffer.alloc(0);
    }
  }

  /**
   * è½¬æ¢ä¸ºOpenAI Realtime APIæ ¼å¼
   */
  private convertToRealtimeFormat(audioData: Buffer): Buffer {
    // ç¡®ä¿éŸ³é¢‘æ•°æ®ç¬¦åˆOpenAI Realtime APIçš„è¦æ±‚
    // - é‡‡æ ·ç‡: 24kHz
    // - æ ¼å¼: PCM16
    // - å£°é“: å•å£°é“
    
    if (this.config.format === 'pcm16') {
      // å¦‚æœå·²ç»æ˜¯PCM16æ ¼å¼ï¼Œç›´æ¥è¿”å›
      return audioData;
    }
    
    // å…¶ä»–æ ¼å¼è½¬æ¢é€»è¾‘
    return this.convertToPCM16(audioData);
  }

  /**
   * è½¬æ¢ä¸ºWebRTCæ ¼å¼
   */
  private convertToWebRTCFormat(audioData: Buffer): Buffer {
    // å°†OpenAIçš„éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWebRTCå¯ä»¥å¤„ç†çš„æ ¼å¼
    // é€šå¸¸WebRTCæ”¯æŒå¤šç§æ ¼å¼ï¼Œè¿™é‡Œä¿æŒPCM16
    
    return audioData;
  }

  /**
   * è½¬æ¢ä¸ºPCM16æ ¼å¼
   */
  private convertToPCM16(audioData: Buffer): Buffer {
    // ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ ¹æ®æºæ ¼å¼è¿›è¡Œè½¬æ¢
    switch (this.config.format) {
      case 'g711_ulaw':
        return this.ulawToPCM16(audioData);
      case 'g711_alaw':
        return this.alawToPCM16(audioData);
      default:
        return audioData;
    }
  }

  /**
   * Î¼-lawè½¬PCM16
   */
  private ulawToPCM16(ulawData: Buffer): Buffer {
    const pcmData = Buffer.alloc(ulawData.length * 2);
    
    for (let i = 0; i < ulawData.length; i++) {
      const ulaw = ulawData[i];
      const pcm = this.ulawToPCM(ulaw);
      pcmData.writeInt16LE(pcm, i * 2);
    }
    
    return pcmData;
  }

  /**
   * A-lawè½¬PCM16
   */
  private alawToPCM16(alawData: Buffer): Buffer {
    const pcmData = Buffer.alloc(alawData.length * 2);
    
    for (let i = 0; i < alawData.length; i++) {
      const alaw = alawData[i];
      const pcm = this.alawToPCM(alaw);
      pcmData.writeInt16LE(pcm, i * 2);
    }
    
    return pcmData;
  }

  /**
   * Î¼-lawè§£ç 
   */
  private ulawToPCM(ulaw: number): number {
    const BIAS = 0x84;
    const CLIP = 32635;
    
    ulaw = ~ulaw;
    const sign = (ulaw & 0x80);
    const exponent = (ulaw >> 4) & 0x07;
    const mantissa = ulaw & 0x0F;
    
    let sample = mantissa << (exponent + 3);
    sample += BIAS;
    if (exponent !== 0) sample += (1 << (exponent + 2));
    
    return sign ? -sample : sample;
  }

  /**
   * A-lawè§£ç 
   */
  private alawToPCM(alaw: number): number {
    const sign = (alaw & 0x80);
    let exponent = (alaw >> 4) & 0x07;
    let mantissa = alaw & 0x0F;
    
    if (exponent === 0) {
      mantissa = mantissa << 4;
    } else {
      mantissa = (mantissa << 4) | 0x08;
      mantissa = mantissa << (exponent - 1);
    }
    
    return sign ? -mantissa : mantissa;
  }

  /**
   * åˆ›å»ºéŸ³é¢‘æµè½¬æ¢å™¨
   */
  createAudioTransform(): Transform {
    const self = this;
    return new Transform({
      transform(chunk: Buffer, encoding: BufferEncoding, callback: TransformCallback) {
        try {
          const processedChunk = self.processWebRTCAudio(chunk);
          callback(null, processedChunk);
        } catch (error) {
          const err: Error = error instanceof Error ? error : new Error(String(error));
          callback(err);
         }
      }
    });
  }

  /**
   * è·å–éŸ³é¢‘é…ç½®
   */
  getConfig(): AudioConfig {
    return { ...this.config };
  }

  /**
   * æ›´æ–°éŸ³é¢‘é…ç½®
   */
  updateConfig(newConfig: Partial<AudioConfig>): void {
    this.config = { ...this.config, ...newConfig };
    console.log('ğŸ”§ éŸ³é¢‘é…ç½®å·²æ›´æ–°:', this.config);
  }

  /**
   * è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
   */
  calculateDuration(audioData: Buffer): number {
    const bytesPerSample = this.config.bitDepth / 8;
    const totalSamples = audioData.length / (bytesPerSample * this.config.channels);
    return (totalSamples / this.config.sampleRate) * 1000;
  }

  /**
   * éªŒè¯éŸ³é¢‘æ•°æ®æ ¼å¼
   */
  validateAudioData(audioData: Buffer): boolean {
    if (!audioData || audioData.length === 0) {
      return false;
    }
    
    const bytesPerSample = this.config.bitDepth / 8;
    const expectedAlignment = bytesPerSample * this.config.channels;
    
    return audioData.length % expectedAlignment === 0;
  }
}

export default AudioProcessor;